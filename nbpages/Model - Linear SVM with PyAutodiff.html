<html>
<head>
<style type="text/css">
/**
 * HTML5 âœ° Boilerplate
 *
 * style.css contains a reset, font normalization and some base styles.
 *
 * Credit is left where credit is due.
 * Much inspiration was taken from these projects:
 * - yui.yahooapis.com/2.8.1/build/base/base.css
 * - camendesign.com/design/
 * - praegnanz.de/weblog/htmlcssjs-kickstart
 */


/**
 * html5doctor.com Reset Stylesheet (Eric Meyer's Reset Reloaded + HTML5 baseline)
 * v1.6.1 2010-09-17 | Authors: Eric Meyer & Richard Clark
 * html5doctor.com/html-5-reset-stylesheet/
 */

html, body, div, span, object, iframe,
h1, h2, h3, h4, h5, h6, p, blockquote, pre,
abbr, address, cite, code, del, dfn, em, img, ins, kbd, q, samp,
small, strong, sub, sup, var, b, i, dl, dt, dd, ol, ul, li,
fieldset, form, label, legend,
table, caption, tbody, tfoot, thead, tr, th, td,
article, aside, canvas, details, figcaption, figure,
footer, header, hgroup, menu, nav, section, summary,
time, mark, audio, video {
  margin: 0;
  padding: 0;
  border: 0;
  font-size: 100%;
  font: inherit;
  vertical-align: baseline;
}

sup { vertical-align: super; }
sub { vertical-align: sub; }

article, aside, details, figcaption, figure,
footer, header, hgroup, menu, nav, section {
  display: block;
}

blockquote, q { quotes: none; }

blockquote:before, blockquote:after,
q:before, q:after { content: ""; content: none; }

ins { background-color: #ff9; color: #000; text-decoration: none; }

mark { background-color: #ff9; color: #000; font-style: italic; font-weight: bold; }

del { text-decoration: line-through; }

abbr[title], dfn[title] { border-bottom: 1px dotted; cursor: help; }

table { border-collapse: collapse; border-spacing: 0; }

hr { display: block; height: 1px; border: 0; border-top: 1px solid #ccc; margin: 1em 0; padding: 0; }

input, select { vertical-align: middle; }


/**
 * Font normalization inspired by YUI Library's fonts.css: developer.yahoo.com/yui/
 */

body { font:13px/1.231 sans-serif; *font-size:small; } /* Hack retained to preserve specificity */
select, input, textarea, button { font:99% sans-serif; }

/* Normalize monospace sizing:
   en.wikipedia.org/wiki/MediaWiki_talk:Common.css/Archive_11#Teletype_style_fix_for_Chrome */
pre, code, kbd, samp { font-family: monospace, sans-serif; }

em,i { font-style: italic; }
b,strong { font-weight: bold; }

</style>
<style type="text/css">

/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
 
.hbox {
	display: -webkit-box;
	-webkit-box-orient: horizontal;
	-webkit-box-align: stretch;
 
	display: -moz-box;
	-moz-box-orient: horizontal;
	-moz-box-align: stretch;
 
	display: box;
	box-orient: horizontal;
	box-align: stretch;
}
 
.hbox > * {
	-webkit-box-flex: 0;
	-moz-box-flex: 0;
	box-flex: 0;
}
 
.vbox {
	display: -webkit-box;
	-webkit-box-orient: vertical;
	-webkit-box-align: stretch;
 
	display: -moz-box;
	-moz-box-orient: vertical;
	-moz-box-align: stretch;
 
	display: box;
	box-orient: vertical;
	box-align: stretch;
}
 
.vbox > * {
	-webkit-box-flex: 0;
	-moz-box-flex: 0;
	box-flex: 0;
}
  
.reverse {
	-webkit-box-direction: reverse;
	-moz-box-direction: reverse;
	box-direction: reverse;
}
 
.box-flex0 {
	-webkit-box-flex: 0;
	-moz-box-flex: 0;
	box-flex: 0;
}
 
.box-flex1, .box-flex {
	-webkit-box-flex: 1;
	-moz-box-flex: 1;
	box-flex: 1;
}
 
.box-flex2 {
	-webkit-box-flex: 2;
	-moz-box-flex: 2;
	box-flex: 2;
}
 
.box-group1 {
	-webkit-box-flex-group: 1;
	-moz-box-flex-group: 1;
	box-flex-group: 1;
}
 
.box-group2 {
	-webkit-box-flex-group: 2;
	-moz-box-flex-group: 2;
	box-flex-group: 2;
}
 
.start {
	-webkit-box-pack: start;
	-moz-box-pack: start;
	box-pack: start;
}
 
.end {
	-webkit-box-pack: end;
	-moz-box-pack: end;
	box-pack: end;
}
 
.center {
	-webkit-box-pack: center;
	-moz-box-pack: center;
	box-pack: center;
}

</style>
<style type="text/css">
/**
 * Primary styles
 *
 * Author: IPython Development Team
 */


body {
    overflow: hidden;
}

span#save_widget {
    padding: 5px;
    margin: 0px 0px 0px 300px;
    display:inline-block;
}

span#notebook_name {
    height: 1em;
    line-height: 1em;
    padding: 3px;
    border: none;
    font-size: 146.5%;
}

.ui-menubar-item .ui-button .ui-button-text {
    padding: 0.4em 1.0em;
    font-size: 100%;
}

.ui-menu {
  -moz-box-shadow:    0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow:         0px 6px 10px -1px #adadad;
}

.ui-menu .ui-menu-item a {
    border: 1px solid transparent;
    padding: 2px 1.6em;
}

.ui-menu .ui-menu-item a.ui-state-focus {
    margin: 0;
}

.ui-menu hr {
    margin: 0.3em 0;
}

#menubar_container {
    position: relative;
}

#notification {
    position: absolute;
    right: 3px;
    top: 3px;
    height: 25px;
    padding: 3px 6px;
    z-index: 10;
}

#toolbar {
    padding: 3px 15px;
}

#cell_type {
    font-size: 85%;
}


div#main_app {
    width: 100%;
    position: relative;
}

span#quick_help_area {
    position: static;
    padding: 5px 0px;
    margin: 0px 0px 0px 0px;
}

.help_string {
    float: right;
    width: 170px;
    padding: 0px 5px;
    text-align: left;
    font-size: 85%;
}

.help_string_label {
    float: right;
    font-size: 85%;
}

div#notebook_panel {
    margin: 0px 0px 0px 0px;
    padding: 0px;
}

div#notebook {
    overflow-y: scroll;
    overflow-x: auto;
    width: 100%;
    /* This spaces the cell away from the edge of the notebook area */
    padding: 5px 5px 15px 5px;
    margin: 0px;
    background-color: white;
}

div#pager_splitter {
    height: 8px;
}

div#pager {
    padding: 15px;
    overflow: auto;
    display: none;
}

div.ui-widget-content {
    border: 1px solid #aaa;
    outline: none;
}

.cell {
    border: 1px solid transparent;
}

div.cell {
    width: 100%;
    padding: 5px 5px 5px 0px;
    /* This acts as a spacer between cells, that is outside the border */
    margin: 2px 0px 2px 0px;
}

div.code_cell {
    background-color: white;
}

/* any special styling for code cells that are currently running goes here */
div.code_cell.running {
}

div.prompt {
    /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
    width: 11ex;
    /* This 0.4em is tuned to match the padding on the CodeMirror editor. */
    padding: 0.4em;
    margin: 0px;
    font-family: monospace;
    text-align:right;
}

div.input {
    page-break-inside: avoid;
}

/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
    color: black;
    border: 1px solid #ddd;
    border-radius: 3px;
    background: #f7f7f7;
}

div.input_prompt {
    color: navy;
    border-top: 1px solid transparent;
}

div.output_wrapper {
    /* This is a spacer between the input and output of each cell */
    margin-top: 5px;
    margin-left: 5px;
    /* FF needs explicit width to stretch */
    width: 100%;
    /* this position must be relative to enable descendents to be absolute within it */
    position: relative;
}

/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  
  overflow: auto;
  border-radius: 3px;
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, .8);
}

/* output div while it is collapsed */
div.output_collapsed {
  margin-right: 5px;
}

div.out_prompt_overlay {
  height: 100%;
  padding: 0px;
  position: absolute;
  border-radius: 3px;
}

div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}

div.output_prompt {
    color: darkred;
    /* 5px right shift to account for margin in parent container */
    margin: 0 5px 0 -5px;
}

/* This class is the outer container of all output sections. */
div.output_area {
    padding: 0px;
    page-break-inside: avoid;
}

/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
    padding: 0.4em 0.4em 0.4em 0.4em;
}

/* The rest of the output_* classes are for special styling of the different
   output types */

/* all text output has this class: */
div.output_text {
    text-align: left;
    color: black;
    font-family: monospace;
}

/* stdout/stderr are 'text' as well as 'stream', but pyout/pyerr are *not* streams */
div.output_stream {
    padding-top: 0.0em;
    padding-bottom: 0.0em;
}
div.output_stdout {
}
div.output_stderr {
    background: #fdd; /* very light red background for stderr */
}

div.output_latex {
    text-align: left;
    color: black;
}

div.output_html {
}

div.output_png {
}

div.output_jpeg {
}

div.text_cell {
    background-color: white;
    padding: 5px 5px 5px 5px;
}

div.text_cell_input {
    color: black;
    border: 1px solid #ddd;
    border-radius: 3px;
    background: #f7f7f7;
}

div.text_cell_render {
    font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;
    outline: none;
    resize: none;
    width:  inherit;
    border-style: none;
    padding: 5px;
    color: black;
}

/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font. 
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */

.CodeMirror {
    line-height: 1.231;  /* Changed from 1em to our global default */
}

.CodeMirror-scroll {
    height: auto;     /* Changed to auto to autogrow */
    /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
    /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
    overflow-y: hidden;
    overflow-x: auto; /* Changed from auto to remove scrollbar */
}

/* CSS font colors for translated ANSI colors. */


.ansiblack {color: black;}
.ansired {color: darkred;}
.ansigreen {color: darkgreen;}
.ansiyellow {color: brown;}
.ansiblue {color: darkblue;}
.ansipurple {color: darkviolet;}
.ansicyan {color: steelblue;}
.ansigrey {color: grey;}
.ansibold {font-weight: bold;}

.completions {
    position: absolute;
    z-index: 10;
    overflow: hidden;
    border: 1px solid grey;
}

.completions select {
    background: white;
    outline: none;
    border: none;
    padding: 0px;
    margin: 0px;
    overflow: auto;
    font-family: monospace;
}

option.context {
  background-color: #DEF7FF;
}
option.introspection {
  background-color: #EBF4EB;
}

/*fixed part of the completion*/
.completions p b {
    font-weight:bold;
}

.completions p {
    background: #DDF;
    /*outline: none;
    padding: 0px;*/
    border-bottom: black solid 1px;
    padding: 1px;
    font-family: monospace;
}

pre.dialog {
    background-color: #f7f7f7;
    border: 1px solid #ddd;
    border-radius: 3px;
    padding: 0.4em;
    padding-left: 2em;
}

p.dialog {
    padding : 0.2em;
}

.shortcut_key {
    display: inline-block;
    width: 15ex;
    text-align: right;
    font-family: monospace;
}

.shortcut_descr {
}

/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre, code, kbd, samp { white-space: pre-wrap; }

#fonttest {
    font-family: monospace;
}

</style>
<style type="text/css">
.rendered_html {color: black;}
.rendered_html em {font-style: italic;}
.rendered_html strong {font-weight: bold;}
.rendered_html u {text-decoration: underline;}
.rendered_html :link { text-decoration: underline }
.rendered_html :visited { text-decoration: underline }
.rendered_html h1 {font-size: 197%; margin: .65em 0; font-weight: bold;}
.rendered_html h2 {font-size: 153.9%; margin: .75em 0; font-weight: bold;}
.rendered_html h3 {font-size: 123.1%; margin: .85em 0; font-weight: bold;}
.rendered_html h4 {font-size: 100% margin: 0.95em 0; font-weight: bold;}
.rendered_html h5 {font-size: 85%; margin: 1.5em 0; font-weight: bold;}
.rendered_html h6 {font-size: 77%; margin: 1.65em 0; font-weight: bold;}
.rendered_html ul {list-style:disc; margin: 1em 2em;}
.rendered_html ul ul {list-style:square; margin: 0em 2em;}
.rendered_html ul ul ul {list-style:circle; margin-left: 0em 2em;}
.rendered_html ol {list-style:upper-roman; margin: 1em 2em;}
.rendered_html ol ol {list-style:upper-alpha; margin: 0em 2em;}
.rendered_html ol ol ol {list-style:decimal; margin: 0em 2em;}
.rendered_html ol ol ol ol {list-style:lower-alpha; margin 0em 2em;}
.rendered_html ol ol ol ol ol {list-style:lower-roman; 0em 2em;}

.rendered_html hr {
    color: black;
    background-color: black;
}

.rendered_html pre {
    margin: 1em 2em;
}

.rendered_html blockquote {
    margin: 1em 2em;
}

.rendered_html table {
    border: 1px solid black;
    border-collapse: collapse;
    margin: 1em 2em;
}

.rendered_html td {
    border: 1px solid black;
    text-align: left;
    vertical-align: middle;
    padding: 4px;
}

.rendered_html th {
    border: 1px solid black;
    text-align: left;
    vertical-align: middle;
    padding: 4px;
    font-weight: bold;
}

.rendered_html tr {
    border: 1px solid black;
}    

.rendered_html p + p {
    margin-top: 1em;
}


</style>
<style type="text/css">
/* Overrides of notebook CSS for static HTML export

*/
body {
  overflow: visible;
  padding: 8px;
}
.input_area {
  padding: 0.4em;
}

</style>
<meta charset="UTF-8">
<style type="text/css">
.highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
</style>
<script src="https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript">

</script>
<script type="text/javascript">
init_mathjax = function() {
    if (window.MathJax) {
        // MathJax loaded
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
            },
            displayAlign: 'left', // Change this to 'center' to center equations.
            "HTML-CSS": {
                styles: {'.MathJax_Display': {"margin": 0}}
            }
        });
        MathJax.Hub.Queue(["Typeset",MathJax.Hub]);
    }
}
init_mathjax();
</script>
</head>
<body>
<div class="text_cell_render border-box-sizing rendered_html">
<h1>Linear Support Vector Machine</h1>
<p>The linear support vector machine (SVM) is a linear classifier parametrized by a matrix of weights $W$ and a bias vector $\mathbf{b}$.  We will develop the multiclass "One vs. All" linear support vector machine, which is a concatentation of two-class support vector machines. We will suppose that our label set is the non-negative integers up to some maximum L.</p>
<p>There are other ways of setting up a multi-class SVM, such using the Crammer-Singer loss or
<a href="http://www.machinelearning.org/proceedings/icml2007/papers/381.pdf">LaRank</a>.
Despite theoretical limitations (lack of consistency!?) the approach is widely used.
See <a href="http://hunch.net/~jl/projects/reductions/reductions.html">John Langford's page on machine learning reductions</a>
for more perspectives on multi-class SVMs.</p>
<p>Deep architectures for classification are typically formed by classifying learned features with a
linear classifier such as an SVM or logistic regression model.
We will begin our exploration of deep architectures with the shallowest model of all: the linear SVM.</p>
<p>The Deep Learning Tutorials provide a good complementary introduction to 
<a href="http://deeplearning.net/tutorial/logreg.html">logistic regression</a>.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="c"># initialize the workspace by importing several symbols</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">arange</span><span class="p">,</span> <span class="n">dot</span><span class="p">,</span> <span class="n">maximum</span><span class="p">,</span> <span class="n">ones</span><span class="p">,</span> <span class="n">tanh</span><span class="p">,</span> <span class="n">zeros</span>
<span class="kn">from</span> <span class="nn">numpy.random</span> <span class="kn">import</span> <span class="n">randn</span>

<span class="kn">from</span> <span class="nn">skdata</span> <span class="kn">import</span> <span class="n">mnist</span>
<span class="kn">import</span> <span class="nn">autodiff</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">util</span> <span class="kn">import</span> <span class="n">show_filters</span>
<span class="k">except</span><span class="p">:</span>
    <span class="k">print</span> <span class="s">&#39;WARNING: show_filters will not work&#39;</span>
    <span class="k">def</span> <span class="nf">show_filters</span><span class="p">(</span><span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">):</span> <span class="k">pass</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="c"># -- load and prepare the data set (even download if necessary)</span>
<span class="n">dtype</span> <span class="o">=</span> <span class="s">&#39;float32&#39;</span>
<span class="n">n_examples</span> <span class="o">=</span> <span class="mi">50000</span>
<span class="n">n_classes</span> <span class="o">=</span> <span class="mi">10</span>         <span class="c"># -- denoted L in the math expressions</span>
<span class="n">img_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>

<span class="n">data_view</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">views</span><span class="o">.</span><span class="n">OfficialVectorClassification</span><span class="p">(</span><span class="n">x_dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">data_view</span><span class="o">.</span><span class="n">all_vectors</span><span class="p">[</span><span class="n">data_view</span><span class="o">.</span><span class="n">fit_idxs</span><span class="p">[:</span><span class="n">n_examples</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data_view</span><span class="o">.</span><span class="n">all_labels</span><span class="p">[</span><span class="n">data_view</span><span class="o">.</span><span class="n">fit_idxs</span><span class="p">[:</span><span class="n">n_examples</span><span class="p">]]</span>
</pre></div>

</div>
</div>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Supposing that our input is a vector (generally a <em>feature vector</em>) $\mathbf{x}$, the prediction $l^*$ of the OVA-SVM is the argmax of the affine function:</p>
<p>$$
l^<em> = \operatorname</em>{argmax}_{l=0}^{L} (\mathbf{x} W_l + \mathbf{b}_l)
$$</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="k">def</span> <span class="nf">ova_svm_prediction</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h2>Training an SVM</h2>
<p>The most standard way of training an SVM is to maximize the <em>margin</em> on training data.
The <em>margin</em> is always defined in the two-class case (where $y \in \{-1, +1\}$) 
as $y * (xW + b)$.
The affine function parametrized by $W$ and $b$ defines a hyper-plane where $\mathbf{x}W + b = 0$ that the SVM interprets as a decision surface.
The <em>margin</em> represents how far away $\mathbf{x}W+b$ is from being on the wrong side of the decision surface: large positive values mean there is a safe distance ("margin of error?"), negative values mean that the decision surface is actually incorrect for the given $\mathbf{x}$.</p>
<p>The most standard sense in which SVMs maximize margin is via the <em>hinge loss</em>. The hinge loss of margin value $u$ is defined as</p>
<p>$$
\mathrm{hinge}(u) = \max(0, 1-u)
$$</p>
<p>By maximizing the average hinge loss of the margin of training examples, we maximize a tight convex upper bound on the mis-classification rate (zero-one loss), and can 
get a good binary classifier using fast algorithms for convex optimization.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="k">def</span> <span class="nf">hinge</span><span class="p">(</span><span class="n">u</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">u</span><span class="p">)</span>

<span class="n">ugrid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plot</span><span class="p">(</span><span class="n">ugrid</span><span class="p">,</span> <span class="n">hinge</span><span class="p">(</span><span class="n">ugrid</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s">&#39;hinge loss&#39;</span><span class="p">)</span>
<span class="n">plot</span><span class="p">(</span><span class="n">ugrid</span><span class="p">,</span> <span class="n">ugrid</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">&#39;zero-one loss&#39;</span><span class="p">)</span>
<span class="n">legend</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h3>Multiclass SVM</h3>
<p>In the multiclass case, it is not clear what the "correct" margin definition should be, and several useful ones have been proposed.
For the rest of this tutorial we'll develop the "one vs. all" multiclass SVM, sometimes called an OVA-SVM.</p>
<p>In the OVA-SVM, the training objective is defined by $L$ independent SVMs.
We will train an OVA-SVM by converting the integer-valued labels
$y$ to $Y \in \{-1, +1\}^{N \times L}$ and training $L$ SVMs at once.
The $L$ columns of $Y$ represent binary classification tasks.
The $L$ columns of $W$ and $L$ elements of $\mathbf{b}$ store the parameters of the $L$ SVMs.</p>
<p>The [unregularized] training objective is:</p>
<p>$$
\mathcal{L}(\mathcal{D}; W, \mathbf{b}) =
\frac{1}{N}
\sum_{(\mathbf{x}^{(i)}, Y^{(i)}) \in \mathcal{D}}
~
\sum_{l=1}^{L}
~
\max \left( 0, 1 - Y^{(i)}_l (\mathbf{x}^{(i)} W_l + \mathbf{b}_l) \right)
$$</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="c"># -- prepare a &quot;1-hot&quot; version of the labels, denoted Y in the math</span>
<span class="n">y1</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">ones</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">n_classes</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
<span class="n">y1</span><span class="p">[</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)),</span> <span class="n">y</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="k">def</span> <span class="nf">ova_svm_cost</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y1</span><span class="p">):</span>
    <span class="c"># -- one vs. all linear SVM loss</span>
    <span class="n">margin</span> <span class="o">=</span> <span class="n">y1</span> <span class="o">*</span> <span class="p">(</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="n">hinge</span><span class="p">(</span><span class="n">margin</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">cost</span>
</pre></div>

</div>
</div>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>The training itself consists in minimizing the objective $\mathcal{L}(\mathcal{D}; W, b)$ with respect to $W$ and $b$.  The criterion is convex, so it doesn't much matter where we start. Zero works well in practice.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="c"># initialize the model</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">n_classes</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">n_classes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are many specialized SVM solvers available, but they tend to be most helpful for non-linear SVMs.  In the linear case a simple combination of stochastic gradient descent (SGD) and BFGS can be very effective.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="c"># -- do n_online_loops passes through the data set doing SGD</span>
<span class="c">#    This can be faster at the beginning than L-BFGS</span>
<span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">online_batch_size</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">n_online_epochs</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">n_batches</span> <span class="o">=</span> <span class="n">n_examples</span> <span class="o">/</span> <span class="n">online_batch_size</span>
<span class="n">W</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">autodiff</span><span class="o">.</span><span class="n">fmin_sgd</span><span class="p">(</span><span class="n">ova_svm_cost</span><span class="p">,</span> <span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span>
            <span class="n">streams</span><span class="o">=</span><span class="p">{</span>
                <span class="s">&#39;x&#39;</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">n_batches</span><span class="p">,</span> <span class="n">online_batch_size</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])),</span>
                <span class="s">&#39;y1&#39;</span><span class="p">:</span> <span class="n">y1</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">n_batches</span><span class="p">,</span> <span class="n">online_batch_size</span><span class="p">,</span> <span class="n">y1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))},</span>
            <span class="n">loops</span><span class="o">=</span><span class="n">n_online_epochs</span><span class="p">,</span>
            <span class="n">step_size</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
            <span class="n">print_interval</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
            <span class="p">)</span>
<span class="k">print</span> <span class="s">&#39;SGD took </span><span class="si">%.2f</span><span class="s"> seconds&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span><span class="p">)</span>
<span class="n">show_filters</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">img_shape</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="c"># -- L-BFGS optimization of our SVM cost.</span>

<span class="k">def</span> <span class="nf">batch_criterion</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">ova_svm_cost</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y1</span><span class="p">)</span>

<span class="n">W</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">autodiff</span><span class="o">.</span><span class="n">fmin_l_bfgs_b</span><span class="p">(</span><span class="n">batch_criterion</span><span class="p">,</span> <span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="n">maxfun</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">iprint</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="k">print</span> <span class="s">&#39;final_cost&#39;</span><span class="p">,</span> <span class="n">batch_criterion</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="c"># -- N. B. the output from this command comes from Fortran, so iPython does not see it.</span>
<span class="c">#    To monitor progress, look at the terminal from which you launched ipython</span>
<span class="n">show_filters</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">img_shape</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h2>Testing the SVM</h2>
<p>Once the a classifier has been trained, we can test it for generalization accuracy on the test set. We test it by making predictions for the examples in the test set and counting up the number of classification mistakes.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="n">train_predictions</span> <span class="o">=</span> <span class="n">ova_svm_prediction</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">train_errors</span> <span class="o">=</span> <span class="n">y</span> <span class="o">!=</span> <span class="n">train_predictions</span>
<span class="k">print</span> <span class="s">&#39;Current train set error rate&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_errors</span><span class="p">)</span>

<span class="n">test_predictions</span> <span class="o">=</span> <span class="n">ova_svm_prediction</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">data_view</span><span class="o">.</span><span class="n">all_vectors</span><span class="p">[</span><span class="n">data_view</span><span class="o">.</span><span class="n">tst_idxs</span><span class="p">])</span>
<span class="n">test_errors</span> <span class="o">=</span> <span class="n">data_view</span><span class="o">.</span><span class="n">all_labels</span><span class="p">[</span><span class="n">data_view</span><span class="o">.</span><span class="n">tst_idxs</span><span class="p">]</span> <span class="o">!=</span> <span class="n">test_predictions</span>
<span class="k">print</span> <span class="s">&#39;Current test set error rate&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_errors</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h2>SVM Summary</h2>
<p>The linear Support Vector Machine (SVM) is an accurate and quick-to-train linear classifier.
We looked a multiclass variant called a "One vs. All" SVM,
parameterized by a matrix $W$ of weights and a vector $\mathbf{b}$ of biases.
A linear SVM can be trained by gradient descent;
whether SGD or L-BFGS works faster depends on the size of the data set and accuracy desired from the minimization process. A few iterations of SGD followed by refinement by L-BFGS is a fairly robust strategy.</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h3>Exercise: L1 and L2 regularization</h3>
<p>Typically linear SVMs are L2-regularized. That means that in addition to $\mathcal{L}$, we minimize the sum of the squared elements of $W$:</p>
<p>$$
\mathcal{L}_{\ell_2}(\mathcal{D}; W, b) = \mathcal{L}(\mathcal{D}; W, b) + \alpha ||W||_2^2
$$</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="k">def</span> <span class="nf">ova_svm_cost_l2</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s">&#39;implement me&#39;</span><span class="p">)</span>

<span class="c"># re-run the SGD and LBFGS training fragments after filling</span>
<span class="c"># in this function body to implement an L2-regularized SVM.</span>

<span class="c"># In cases where the training data are linearly separable, this can be very important.</span>
<span class="c"># How big does \alpha have to be to make any difference?</span>
</pre></div>

</div>
</div>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h3>Exercise: Data Z-Normalization</h3>
<p>Although the optimization of an SVM is a convex problem, the efficiency and stopping criteria of both SGD and L-BFGS are generally improved by centering and normalizing each input feature beforehand. The procedure is simple: subtract off the training set mean of each feature and divide by the standard deviation.</p>
<p>How does this affect the behavior of SGD and L-BFGS?</p>
<p>How should you deal with features whose standard deviation is very small? What about when it is 0?</p>
</div>

<div class="text_cell_render border-box-sizing rendered_html">
<h3>Exercise: Different Data Sets</h3>
<p>We have been using MNIST so far. How good is a linear classifier on other datasets that are typically used in deep learning?
The following two code fragments bring in access to the CIFAR-10 and SVHN data sets.
You'll have to access the <code>shape</code> attribute of the training images to figure out how many visible units there are, and then re-allocate <code>W</code> before repeating the training and testing processes.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="kn">from</span> <span class="nn">skdata</span> <span class="kn">import</span> <span class="n">cifar10</span>
<span class="n">n_examples</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="c"># -- RECOMMENDED: restart the IPython kernel to clear out memory</span>
<span class="n">data_view</span> <span class="o">=</span> <span class="n">cifar10</span><span class="o">.</span><span class="n">view</span><span class="o">.</span><span class="n">OfficialVectorClassification</span><span class="p">(</span><span class="n">x_dtype</span><span class="o">=</span><span class="s">&#39;float32&#39;</span><span class="p">,</span> <span class="n">n_train</span><span class="o">=</span><span class="n">n_examples</span><span class="p">)</span>

<span class="c"># Write the rest of the answer here:</span>
<span class="c"># - define x and y for training</span>

<span class="c"># Repeat the training steps in the code fragments above to train a linear SVM for CIFAR10</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="kn">from</span> <span class="nn">skdata</span> <span class="kn">import</span> <span class="n">svhn</span>
<span class="n">n_examples</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="c"># -- RECOMMENDED: restart the IPython kernel to clear out memory</span>
<span class="n">data_view</span> <span class="o">=</span> <span class="n">svhn</span><span class="o">.</span><span class="n">view</span><span class="o">.</span><span class="n">CroppedDigitsView2</span><span class="p">(</span><span class="n">x_dtype</span><span class="o">=</span><span class="s">&#39;float32&#39;</span><span class="p">,</span> <span class="n">n_train</span><span class="o">=</span><span class="n">n_examples</span><span class="p">)</span>

<span class="c"># Write the rest of the answer here:</span>
<span class="c"># - define x and y for training</span>

<span class="c"># Repeat the training steps in the code fragments above to train a linear SVM for</span>
<span class="c"># Street View House Numbers (SVHN)</span>
</pre></div>

</div>
</div>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Bonus: Pixel colors in cifar10 and svhn are encoded as RGB triples.  There are many other ways of representing color. Some of these are linearly related to RGB, others non-linearly.
The <a href="http://scikits-image.org/">scikit-image</a> project defines a number of color-conversion routines.
Are any of these color representations better than RGB for image classification?</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="kn">from</span> <span class="nn">skimage.color</span> <span class="kn">import</span> <span class="n">convert_colorspace</span>

<span class="c"># Write your answer here</span>
<span class="c"># use convert_colorspace to define new versions of the training and testing images.</span>

<span class="c"># Hint - you&#39;ll have to un-rasterize the x matrix into a N-dimensional array</span>
<span class="c">#        n. examples x n. rows x n. cols x n. channels</span>
</pre></div>

</div>
</div>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h3>Exercise: Variations on the Hinge Loss</h3>
<p>You don't have to use the hinge loss to train a linear classifier. Other popular loss functions include the squared hinge loss, the "Huberized" hinge loss, and the exponential function.  These functions are continuously differentiable, which you might expect to help for gradient-based optimization. Does it help? How else are these functions different? In what cases would it matter?</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="c"># Write your answer here</span>
</pre></div>

</div>
</div>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h3>Exercise: Crammer-Singer Loss for Multiclass SVM</h3>
<p>TODO: VERIFY THIS QUESTION</p>
<p>The One vs. All SVM suffers, in theory, from a lack of Bayes consistency.
The <em>Crammer-Singer loss</em> defines the multiclass training objective differently, in a way that is Bayes-consistent.</p>
<p>To define the Crammer-Singer loss let's define
$\mathbf{h} = \mathbf{x}W + \mathbf{b}$,
and look at $\mathbf{m}$ where 
$\mathbf{m}_j = 1 - \mathbf{h}_l - \mathbf{h}_j $
for all elements $j$ that are not the correct label $l$.</p>
<p>The Crammer-Singer objective is to minimize the expectation over the dataset of
$\sum_j max(0, \mathbf{m}_{j})$.</p>
<p>Can you code this up as a training criterion and use it?</p>
<p>HINT: Start with the case of pure stochastic gradient descent, I think the batch case requires numpy's <em>advanced indexing</em> which not currently supported by <code>autodiff</code>.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="c"># Write your answer here</span>
</pre></div>

</div>
</div>
</div>
</body>
</html>